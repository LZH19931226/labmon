<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <springProperty scope="context" name="appName"
                    source="spring.application.name" defaultValue="HC-datapase-ms" />
    <springProperty scope="context" name="type"
                    source="msConfig.logging.path" defaultValue="logs" />
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    <!-- 日志输出的通道 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <!-- encoder 默认配置为PatternLayoutEncoder -->
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n
            </pattern>
        </encoder>
    </appender>
    <appender name="LOGSTASH"  class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>172.24.58.152:9600</destination>
        <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>
<!--    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">-->
<!--        <destination>172.24.58.152:9600</destination>-->
<!--        <queueSize>1048576</queueSize>-->
<!--        <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">-->
<!--            <providers>-->
<!--                <timestamp>-->
<!--                    <timeZone>UTC</timeZone>-->
<!--                </timestamp>-->
<!--                <pattern>-->
<!--                    <pattern>-->
<!--                        {-->
<!--                        "severity":"%level",-->
<!--                        "service": "%contextName",-->
<!--                        "pid": "${PID:-}",-->
<!--                        "thread": "%thread",-->
<!--                        "class": "%logger{40}",-->
<!--                        "rest": "%message->%ex{full}"-->
<!--                        }-->
<!--                    </pattern>-->
<!--                </pattern>-->
<!--            </providers>-->
<!--        </encoder>-->
<!--    </appender>-->
    <logger name="jdbc.sqltiming" level="DEBUG"/>
    <logger name="com.ibatis" level="DEBUG" />
    <logger name="com.ibatis.common.jdbc.SimpleDataSource" level="DEBUG" />
    <logger name="com.ibatis.common.jdbc.ScriptRunner" level="DEBUG" />
    <logger name="com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate" level="DEBUG" />
    <logger name="java.sql.Connection" level="DEBUG" />
    <logger name="java.sql.Statement" level="DEBUG" />
    <logger name="java.sql.PreparedStatement" level="DEBUG" />
    <root level="INFO">
            <appender-ref ref="STDOUT"/>
        <appender-ref ref="LOGSTASH"/>
    </root>
</configuration>
<!--<configuration>-->
<!--    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">-->
<!--        <encoder>-->
<!--            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>-->
<!--        </encoder>-->
<!--    </appender>-->

<!--    &lt;!&ndash; This is the kafkaAppender &ndash;&gt;-->
<!--    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">-->
<!--        <encoder>-->
<!--            &lt;!&ndash;<pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>&ndash;&gt;-->
<!--            <pattern>{"_namespace_":"hc-data-pase","_log_":"%msg%n"}</pattern>-->
<!--        </encoder>-->
<!--        <topic>datapase</topic>-->
<!--        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" />-->
<!--        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />-->

<!--        &lt;!&ndash; Optional parameter to use a fixed partition &ndash;&gt;-->
<!--        &lt;!&ndash; <partition>0</partition> &ndash;&gt;-->

<!--        &lt;!&ndash; Optional parameter to include log timestamps into the kafka message &ndash;&gt;-->
<!--        &lt;!&ndash; <appendTimestamp>true</appendTimestamp> &ndash;&gt;-->

<!--        &lt;!&ndash; each <producerConfig> translates to regular kafka-client config (format: key=value) &ndash;&gt;-->
<!--        &lt;!&ndash; producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs &ndash;&gt;-->
<!--        &lt;!&ndash; bootstrap.servers is the only mandatory producerConfig &ndash;&gt;-->
<!--        <producerConfig>bootstrap.servers=172.24.58.150:9092,172.24.58.151:9092,172.24.58.152:9092</producerConfig>-->

<!--        &lt;!&ndash; this is the fallback appender if kafka is not available. &ndash;&gt;-->
<!--    </appender>-->

<!--    <root level="info">-->

<!--        <appender-ref ref="STDOUT"/>&ndash;&gt;-->
<!--        <appender-ref ref="kafkaAppender" />-->
<!--    </root>-->
<!--</configuration>-->